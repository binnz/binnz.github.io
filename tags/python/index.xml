<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on California Dreaming</title>
    <link>https://binnz.github.io/tags/python/</link>
    <description>Recent content in Python on California Dreaming</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 23 Sep 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://binnz.github.io/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Classification Models in Machine Learning</title>
      <link>https://binnz.github.io/post/2019-09-23-classification-models-in-machine-learning/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://binnz.github.io/post/2019-09-23-classification-models-in-machine-learning/</guid>
      <description>&lt;p&gt;Classification is well so common in the area of machine learning and &lt;a href=&#34;https://scikit-learn.org/stable/&#34;&gt;scikit-learn&lt;/a&gt; provides a comprehensive toolkit that can be easily used.
Here I will share some common classification models and how to apply them on a dataset using this good toolkit, while the classification process will cover&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;training and testing&lt;/li&gt;
&lt;li&gt;cross validation and grid serach process&lt;/li&gt;
&lt;li&gt;classification performace display&lt;/li&gt;
&lt;li&gt;plots of area under curves&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Spark MLlib Programming Practice with Airline Dataset</title>
      <link>https://binnz.github.io/post/2018-09-17-spark-mllib/</link>
      <pubDate>Mon, 17 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://binnz.github.io/post/2018-09-17-spark-mllib/</guid>
      <description>&lt;p&gt;In this document, I will build a predictive framework for predicting whether each flight in &lt;code&gt;2006&lt;/code&gt; will be cancelled or not by using the data from &lt;code&gt;2000&lt;/code&gt; to &lt;code&gt;2005&lt;/code&gt; as training data.&lt;/p&gt;
&lt;p&gt;Items to be delivered in this document includes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Show the predictive framework you designed. What features do you extract? What algorithms do you use in the framework?&lt;/li&gt;
&lt;li&gt;Explain the validation method you use.&lt;/li&gt;
&lt;li&gt;Explain the evaluation metric you use and show the effectiveness of your framework (i.e., use confusion matrix)&lt;/li&gt;
&lt;li&gt;Show the validation results and give a summary of results.&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>Neural Network Architecture and Back-Propagation</title>
      <link>https://binnz.github.io/post/2018-08-19-nn-xor/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://binnz.github.io/post/2018-08-19-nn-xor/</guid>
      <description>&lt;p&gt;The Universal Approximation Theorem states that a 2-layer network can approximate any function, given a complex enough architecture.  That&amp;rsquo;s why we will create a neural network with two neurons in the hidden layer and we will later show how this can model the XOR function.&lt;/p&gt;
&lt;p&gt;In this experiment, we will need to understand and write a simple neural network with backpropagation for “XOR” using only &lt;code&gt;numpy&lt;/code&gt; and other python standard library.&lt;/p&gt;
&lt;p&gt;The code here will allow the user to specify any number of layers and neurons in each layer.  In addition, we are going to use the logistic function as the activity function for this network.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Spark Programming Practice on Hadoop Platform</title>
      <link>https://binnz.github.io/post/2018-06-14-hadoop-spark/</link>
      <pubDate>Thu, 14 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://binnz.github.io/post/2018-06-14-hadoop-spark/</guid>
      <description>&lt;p&gt;The goal of this document is to practice Spark programming on Hadoop platform with the following problems.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;In the text file (&lt;code&gt;Youvegottofindwhatyoulove.txt&lt;/code&gt;), show the &lt;strong&gt;top 30 most frequent occurring words&lt;/strong&gt; and their &lt;strong&gt;average occurrences in a sentence&lt;/strong&gt;   According to the result, what are the characteristics of these words?&lt;/li&gt;
&lt;li&gt;Implement a program to calculate the &lt;strong&gt;average amount in credit card trip for different number of passengers&lt;/strong&gt; which are from one to four passengers in &lt;strong&gt;2017.09&lt;/strong&gt; NYC Yellow Taxi trip data. In NYC Taxi data, the &amp;ldquo;Passenger_count&amp;rdquo; is a driver-entered value. Explain also how you &lt;strong&gt;deal with the data loss issue&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;For each of the above task 1 and 2, &lt;strong&gt;compare the execution time on local worker and yarn cluster&lt;/strong&gt;. Also, give some discussions on your observation.&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>Clustering on New York City Bike Dataset</title>
      <link>https://binnz.github.io/post/2018-01-02-clustering-python/</link>
      <pubDate>Tue, 02 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://binnz.github.io/post/2018-01-02-clustering-python/</guid>
      <description>&lt;p&gt;Our   major   task  here  is   turn   data   into   different   clusters and   explain   what
the   cluster   means.    We will try spatial   clustering, temporal   clustering and the combination of both.&lt;/p&gt;
&lt;p&gt;For each method of clustering, we will&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;try   &lt;strong&gt;at   least   2   values for   each parameter&lt;/strong&gt; in every algorithm.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;explain&lt;/strong&gt; the clustering result.&lt;/li&gt;
&lt;li&gt;make   some &lt;strong&gt;observation&lt;/strong&gt; ,    &lt;strong&gt;compare&lt;/strong&gt;    different   method   and   parameters.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Mining Association Rules on New York City Bike Dataset</title>
      <link>https://binnz.github.io/post/2018-01-01-association-rule-mining/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://binnz.github.io/post/2018-01-01-association-rule-mining/</guid>
      <description>&lt;p&gt;What   we   want   to   do here   is  to design 3 mining tasks with their definitions of transactions and   find   some   rules   behind them.&lt;/p&gt;
&lt;p&gt;For   each   task,   we   should&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Try &lt;strong&gt;at   least   two   discretization   methods&lt;/strong&gt; (divided   by 10, divided   by   20, &amp;hellip;)&lt;/li&gt;
&lt;li&gt;Try &lt;strong&gt;at   least two   algorithms&lt;/strong&gt; (Apriori, FP-growth, &amp;hellip;) to   find   association   rules.&lt;/li&gt;
&lt;li&gt;List the interesting  rules.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compare&lt;/strong&gt;   the   differences   between   them.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Data Preprocessing and Exploring the New York City Bike Dataset</title>
      <link>https://binnz.github.io/post/2017-12-20-data-preprocessing/</link>
      <pubDate>Wed, 20 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://binnz.github.io/post/2017-12-20-data-preprocessing/</guid>
      <description>&lt;p&gt;In this report, I will   do   some   data   preprocessing and   then   get   some   basic information   about   the   dataset, &lt;a href=&#34;https://www.citibikenyc.com/system-data&#34;&gt;New   York   Citi   Bike   Trip   Histories&lt;/a&gt;,    via   tools.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Data Manipulation and Visualization Using Elasticsearch and Kibana</title>
      <link>https://binnz.github.io/post/2017-09-24-elasticsearch-kibana/</link>
      <pubDate>Sun, 24 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://binnz.github.io/post/2017-09-24-elasticsearch-kibana/</guid>
      <description>&lt;p&gt;Elasticsearch is a &lt;strong&gt;distributed&lt;/strong&gt;, &lt;strong&gt;real-time&lt;/strong&gt;, search and analytics platform.&lt;/p&gt;
&lt;p&gt;Using a restful API, Elasticsearch saves data and indexes it automatically. It assigns types to fields and that way a search can be done smartly and quickly using filters and different queries.&lt;/p&gt;
&lt;p&gt;It’s uses &lt;strong&gt;JVM&lt;/strong&gt; in order to be as fast as possible. It distributes indexes in “shards” of data. It replicates shards in different nodes, so it’s distributed and clusters can function even if not all nodes are operational. Adding nodes is super easy and that’s what makes it so scalable.&lt;/p&gt;
&lt;p&gt;ES uses &lt;strong&gt;Lucene&lt;/strong&gt; to solve searches. This is quite an advantage with comparing with, for example, Django query strings. A &lt;strong&gt;restful API&lt;/strong&gt; call allows us to perform searches using json objects as parameters, making it much more flexible and giving each search parameter within the object a different weight, importance and or priority.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Brief Introduction to Popular Data Mining Algorithms</title>
      <link>https://binnz.github.io/post/2017-08-30-python-datamining/</link>
      <pubDate>Wed, 30 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://binnz.github.io/post/2017-08-30-python-datamining/</guid>
      <description>&lt;p&gt;In this article, I will introduce a regression algorithm, linear regression, classical classifiers such as decision trees, naïve Bayes, and support vector machine, and unsupervised clustering algorithms such as k-means, and reinforcement learning techniques, the cross-entropy method, to give only a small glimpse of the variety of machine learning techniques that exist, and we will end this list by introducing neural networks.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Code Example of a Neural Network for The Function XOR</title>
      <link>https://binnz.github.io/post/2017-08-30-nn-xor/</link>
      <pubDate>Wed, 30 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://binnz.github.io/post/2017-08-30-nn-xor/</guid>
      <description>&lt;p&gt;It is a well-known fact, and something we have already mentioned, that 1-layer neural networks cannot predict the function XOR. 1-layer neural nets can only classify linearly separable sets, however, as we have seen, the Universal Approximation Theorem states that a 2-layer network can approximate any function, given a complex enough architecture.&lt;/p&gt;
&lt;p&gt;We will now create a neural network with two neurons in the hidden layer and we will show how this can model the XOR function. However, we will write code that will allow the reader to simply modify it to allow for any number of layers and neurons in each layer, so that the reader can try simulating different scenarios. We are also going to use the hyperbolic tangent as the activity function for this network. To train the network, we will implement the back-propagation algorithm discussed earlier.&lt;/p&gt;
&lt;p&gt;In addition, if you are interested in the mathemetical derivation of this implementation, please see my another post &lt;a href=&#34;../../../2018/08/19/NN-XOR&#34;&gt;&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Unit Testing in Python</title>
      <link>https://binnz.github.io/post/2017-03-30-unit-testing-in-python/</link>
      <pubDate>Thu, 30 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://binnz.github.io/post/2017-03-30-unit-testing-in-python/</guid>
      <description>&lt;p&gt;If you want to be able to change or rewrite your code and know you didn&amp;rsquo;t break anything, proper unit testing is imperative.&lt;/p&gt;
&lt;p&gt;The unittest test framework is python’s xUnit style framework.
It is a standard module that you already have if you’ve got python version 2.1 or greater.   The &lt;code&gt;unittest&lt;/code&gt; module used to be called PyUnit, due to it’s legacy as a xUnit style framework.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>How to Change Schema of a Spark SQL DataFrame?</title>
      <link>https://binnz.github.io/post/2017-03-28-how-to-change-schema-of-a-spark-sql-dataframe/</link>
      <pubDate>Tue, 28 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://binnz.github.io/post/2017-03-28-how-to-change-schema-of-a-spark-sql-dataframe/</guid>
      <description>&lt;p&gt;For the reason that I want to insert &lt;code&gt;rows selected from a table&lt;/code&gt; (&lt;em&gt;df_rows&lt;/em&gt;) to another table, I need to make sure that&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;The schema of the rows selected are the same as the schema of the table
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Since the function &lt;code&gt;pyspark.sql.DataFrameWriter.insertInto&lt;/code&gt;, which inserts the content of the DataFrame to the specified table, requires that the schema of the class:DataFrame is the same as the schema of the table.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Spark SQL Using Python</title>
      <link>https://binnz.github.io/post/2017-03-28-spark-sql-using-python/</link>
      <pubDate>Tue, 28 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://binnz.github.io/post/2017-03-28-spark-sql-using-python/</guid>
      <description>&lt;p&gt;For SQL users, Spark SQL provides state-of-the-art SQL performance and maintains compatibility with Shark/Hive. In particular, like Shark, Spark SQL supports all existing Hive data formats, user-defined functions (UDF), and the Hive metastore. With features that will be introduced in Apache Spark 1.1.0, Spark SQL beats Shark in TPC-DS performance by almost an order of magnitude.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Data Preprocessing on Airline Data</title>
      <link>https://binnz.github.io/post/2017-03-21-data-preprocessing-on-airline-data/</link>
      <pubDate>Tue, 21 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://binnz.github.io/post/2017-03-21-data-preprocessing-on-airline-data/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Data Source and Variable Definition:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://stat-computing.org/dataexpo/2009/the-data.html&#34;&gt;Statistical Computing Statistical Graphics&lt;/a&gt;
We are going to use flight information for &lt;em&gt;2000&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Problems Solving For Installing Scikit-Learn on Windows</title>
      <link>https://binnz.github.io/post/2017-03-20-install-sklearn/</link>
      <pubDate>Mon, 20 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://binnz.github.io/post/2017-03-20-install-sklearn/</guid>
      <description>&lt;p&gt;Sklearn is an &lt;strong&gt;open source Python library&lt;/strong&gt; that implements a range of &lt;strong&gt;machine learning&lt;/strong&gt;, preprocessing, cross-validation and visualization algorithms.   To analyze data with machine learning, sklearn is often used to approach.   Although I already have experience installing sklearn library on Windows, this time I encountered problems installing on my new computer.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
